{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vlm-gym TPU Training Setup\n",
    "\n",
    "Quick setup for training on Colab TPU with low-memory optimizations.\n",
    "\n",
    "**Runtime**: Select `Runtime > Change runtime type > TPU` before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install uv package manager\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "import os\n",
    "os.environ['PATH'] = f\"{os.path.expanduser('~/.cargo/bin')}:{os.environ['PATH']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repo and checkout low-mem-gpu branch\n",
    "%cd /content\n",
    "!git clone https://github.com/sdan/vlm-gym.git\n",
    "%cd vlm-gym\n",
    "!git checkout low-mem-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install dependencies\n!uv venv .venv --python 3.10\n!uv pip install -e .\n\n# Install JAX TPU version\n!pip install jax[tpu] -f https://storage.googleapis.com/jax-releases/libtpu_releases.html"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Clear any TPU locks (if runtime was restarted)\n!sudo pkill -9 python3 || true\n!sudo rm -rf /tmp/libtpu_lockfile /tmp/tpu_logs || true\n\n# Verify TPU setup\nimport os\nos.environ['JAX_PLATFORMS'] = 'tpu'\n\nimport jax\nprint(f\"JAX version: {jax.__version__}\")\nprint(f\"Devices: {jax.devices()}\")\nprint(f\"Device count: {jax.device_count()}\")\nprint(f\"Platform: {jax.devices()[0].platform}\")\n\nif jax.devices()[0].platform != 'tpu':\n    print(\"\\n⚠ WARNING: TPU not detected!\")\n    print(\"Please select: Runtime > Change runtime type > TPU\")\n    raise RuntimeError(\"TPU runtime required\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Download pre-converted checkpoint from GCS\n!mkdir -p checkpoints\n!gsutil -m cp -r gs://geospot/checkpoints/qwen3vl_4b checkpoints/\n\n# Verify download\n!ls -lh checkpoints/qwen3vl_4b/"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training\n",
    "\n",
    "Single rollout + 100 steps with TPU-optimized settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train with low-memory optimizations for TPU v3-8\n# - bf16 params + Adafactor + gradient checkpointing\n# - ppo_minibatch=8 enables pmap across 8 TPU cores (1 sample/core)\n# - Reduced batch_size, max_new_tokens, and vlm_max_pixels to fit in memory\n\n!uv run python -m vlmrl.core.train \\\n  --low_memory=1 \\\n  --model_dir=checkpoints/qwen3vl_4b \\\n  --save_dir=runs/colab-tpu-test \\\n  --wandb_mode=offline \\\n  --wandb_name=colab-tpu-test \\\n  --env_name=geospot \\\n  --env_split=test \\\n  --total_steps=100 \\\n  --batch_size=2 \\\n  --log_interval=10 \\\n  --temperature=0.7 \\\n  --max_new_tokens=24 \\\n  --vlm_max_pixels=65000 \\\n  --ppo_minibatch=8 \\\n  --ppo_epochs=1 \\\n  --optimizer=adafactor \\\n  --learning_rate=1e-6 \\\n  --max_grad_norm=1.0 \\\n  --entropy_coef=0.0 \\\n  --use_ema=0 \\\n  --grad_checkpoint=1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check checkpoint\n",
    "import os\n",
    "ckpt_path = \"runs/colab-tpu-test/train_state.pkl\"\n",
    "if os.path.exists(ckpt_path):\n",
    "    size_mb = os.path.getsize(ckpt_path) / 1024 / 1024\n",
    "    print(f\"✓ Training complete. Checkpoint: {size_mb:.1f} MB\")\n",
    "else:\n",
    "    print(\"✗ No checkpoint found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue Training (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume from checkpoint for longer training\n",
    "!python -m vlmrl.core.train \\\n",
    "  --resume_path=runs/colab-tpu-test/train_state.pkl \\\n",
    "  --total_steps=1000 \\\n",
    "  --low_memory=1 \\\n",
    "  --model_dir=checkpoints/qwen3vl_4b \\\n",
    "  --save_dir=runs/colab-tpu-test"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}